{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 2: Clean Source to Extract Transcripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I've extracted the source for each page of transcripts, I need to extract the actual transcript text. There is unfortunately no overarching, easily digestible method to get a the cleaned transcript, and I relied mostly on trial and error to get the text I wanted. I'm certain there are places where the transcripts are not 100% clean, and I either tried to address this at some later point with more data cleaning, or let it go, because the analysis makes sense with the data in its current state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T01:41:24.900490Z",
     "start_time": "2020-07-21T01:41:24.554800Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, os\n",
    "import re\n",
    "import pickle\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean deBlasio Transcripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting transcripts from source code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process is messy, and I ended up using two different cleaning functions - a second one to catch the ones missed by the first function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T01:41:27.106798Z",
     "start_time": "2020-07-21T01:41:24.902151Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('../data/bdbsource_519.pickle', 'rb') as read_file:\n",
    "    bdbsource_519 = pickle.load(read_file)\n",
    "with open('../data/bdblinks_519.pickle', 'rb') as read_file:\n",
    "    bdblinks_519 = pickle.load(read_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T01:41:27.111357Z",
     "start_time": "2020-07-21T01:41:27.108634Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_text(source_object):\n",
    "    text_list = []\n",
    "    for s in source_object:\n",
    "        text = s.find_all('p')\n",
    "        text_list.append(text)\n",
    "    return text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T01:41:27.254008Z",
     "start_time": "2020-07-21T01:41:27.112771Z"
    }
   },
   "outputs": [],
   "source": [
    "transcript_length = []\n",
    "for i in get_text(bdbsource_519):\n",
    "    transcript_length.append(len(i))\n",
    "transcript_length_array = np.array(transcript_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T01:41:27.393907Z",
     "start_time": "2020-07-21T01:41:27.255941Z"
    }
   },
   "outputs": [],
   "source": [
    "first_transcripts = get_text(bdbsource_519)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T01:41:27.399080Z",
     "start_time": "2020-07-21T01:41:27.395540Z"
    }
   },
   "outputs": [],
   "source": [
    "# These are the indices that need to be re-extracted with get_text2\n",
    "indices = list(np.argwhere(transcript_length_array == 1).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T01:41:27.403206Z",
     "start_time": "2020-07-21T01:41:27.400426Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_text2(source_object):\n",
    "    text_list = []\n",
    "    for s in source_object:\n",
    "        text = s.find('p').parent\n",
    "        text_list.append(text)\n",
    "    return text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T01:41:27.415613Z",
     "start_time": "2020-07-21T01:41:27.405203Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract a better transcript from the bad indices\n",
    "better_transcripts = []\n",
    "for i in indices:\n",
    "    better_transcripts.append(get_text2(bdbsource_519[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T01:41:27.420331Z",
     "start_time": "2020-07-21T01:41:27.417451Z"
    }
   },
   "outputs": [],
   "source": [
    "#replace first transcripts with better_transcripts\n",
    "for (indices, better_transcripts) in zip(indices, better_transcripts):\n",
    "    first_transcripts[indices] = better_transcripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Cleaning Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also wanted to remove html tags, extract the date of the speech, and, in instances where the speech was actually an interview, take only the parts where Mayor de Blasio was speaking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T01:41:27.425473Z",
     "start_time": "2020-07-21T01:41:27.422111Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_html_tags(text):\n",
    "    clean = re.compile('<.*?>')\n",
    "    return re.sub(clean, '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T01:41:27.432742Z",
     "start_time": "2020-07-21T01:41:27.426860Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_bdb(transcript_list, link_list):\n",
    "    date = []\n",
    "    text = []\n",
    "    for i in transcript_list:\n",
    "        cleaned = remove_html_tags(str(i))\n",
    "        if re.search('\\[\\\\n(.+)\\\\n(.+)\\]', cleaned) is not None and re.search('\\[\\\\n(.+)\\\\n(.+)\\]', cleaned) is not None:\n",
    "            date_clean = re.search('\\[\\\\n(.+)\\\\n(.+)\\]', cleaned).group(1)\n",
    "            date.append(date_clean)\n",
    "            text_clean = re.search('\\[\\\\n(.+)\\\\n(.+)\\]', cleaned).group(2)\n",
    "            text.append(text_clean)\n",
    "        else:\n",
    "            date_clean = re.search('\\\\n\\\\n(.+20.{2})\\\\n(.+)\\\\n\\\\ufeff', cleaned).group(1)\n",
    "            date.append(date_clean)\n",
    "            text_clean = re.search('\\\\n\\\\n(.+20.{2})\\\\n(.+)\\\\n\\\\ufeff', cleaned).group(2)\n",
    "            text.append(text_clean)\n",
    "    date = pd.to_datetime(date)\n",
    "    df = pd.DataFrame([date, link_list, text]).T\n",
    "    df.columns = ['date', 'link', 'text']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T01:41:27.789287Z",
     "start_time": "2020-07-21T01:41:27.433903Z"
    }
   },
   "outputs": [],
   "source": [
    "clean = clean_bdb(first_transcripts, bdblinks_519)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T01:41:27.793749Z",
     "start_time": "2020-07-21T01:41:27.790805Z"
    }
   },
   "outputs": [],
   "source": [
    "def take_monologue(transcript):\n",
    "    if len(re.findall('sio:([^:]+)|yor:([^:]+)', str(transcript))) > 0:\n",
    "        return str(re.findall('sio:([^:]+)|yor:([^:]+)', str(transcript)))\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T01:41:27.797613Z",
     "start_time": "2020-07-21T01:41:27.795380Z"
    }
   },
   "outputs": [],
   "source": [
    "toremove = \"'\\\\,\\\"\\[\\(\\]\\)-â€“\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T01:41:27.802485Z",
     "start_time": "2020-07-21T01:41:27.799083Z"
    }
   },
   "outputs": [],
   "source": [
    "punc_lower = lambda x: re.sub('[%s]' % re.escape(toremove), '', x.lower())\n",
    "remove_xa0 = lambda x: x.replace('xa0', '')\n",
    "remove_space = lambda x: x.replace('  ', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T01:41:28.031589Z",
     "start_time": "2020-07-21T01:41:27.804328Z"
    }
   },
   "outputs": [],
   "source": [
    "clean['monologue'] = clean['text'].map(take_monologue).map(punc_lower).map(remove_xa0).map(remove_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T01:41:28.036134Z",
     "start_time": "2020-07-21T01:41:28.032911Z"
    }
   },
   "outputs": [],
   "source": [
    "# Include a column indicating this is a transcript from Mayor de Blasio\n",
    "clean.insert(0, 'speaker', 'de blasio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T01:41:28.072754Z",
     "start_time": "2020-07-21T01:41:28.037401Z"
    }
   },
   "outputs": [],
   "source": [
    "# with open('../data/bdbtranscript_519.pickle', 'wb') as to_write:\n",
    "#     pickle.dump(clean, to_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Cuomo Transcripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract transcripts from source code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get transcript date and text. The text requires multiple sequential cleaning steps, taking a more specific extract each time, and removing text that isn't relevant to the speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T01:41:30.690503Z",
     "start_time": "2020-07-21T01:41:28.074293Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('../data/cuomosource_519.pickle', 'rb') as read_file:\n",
    "    cuomosource_519 = pickle.load(read_file)\n",
    "with open('../data/cuomolinks_519.pickle', 'rb') as read_file:\n",
    "    cuomolinks_519 = pickle.load(read_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T01:41:30.695350Z",
     "start_time": "2020-07-21T01:41:30.691924Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_date(source_object):\n",
    "    date_list = []\n",
    "    for i in source_object:\n",
    "        date = i.find('div', class_=\"published-date\").text\n",
    "        date_clean = re.search('\\\\n\\\\n(.+20.{2})', date).group(1).strip()\n",
    "        date_list.append(date_clean)\n",
    "    return date_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T01:41:31.032083Z",
     "start_time": "2020-07-21T01:41:30.696631Z"
    }
   },
   "outputs": [],
   "source": [
    "cuomo_date = get_date(cuomosource_519)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T01:41:31.036556Z",
     "start_time": "2020-07-21T01:41:31.033609Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_text(source_object):\n",
    "    text_list = []\n",
    "    for s in source_object:\n",
    "        text = s.find('div', class_='field field--name-field-body field--type-text-long field--label-hidden')\n",
    "        text_list.append(text)\n",
    "    return text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T01:41:31.436689Z",
     "start_time": "2020-07-21T01:41:31.040239Z"
    }
   },
   "outputs": [],
   "source": [
    "cuomo_step1 = get_text(cuomosource_519)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T01:41:31.442939Z",
     "start_time": "2020-07-21T01:41:31.438841Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_cuomo(transcript_list):\n",
    "    clean_transcripts = []\n",
    "    for idx, i in enumerate(transcript_list):\n",
    "        cleaned = remove_html_tags(str(i))\n",
    "        if re.search('below:(.+)', cleaned) is not None:\n",
    "            text_clean = re.search('below:(.+)', cleaned).group(1)\n",
    "            clean_transcripts.append(text_clean)\n",
    "        elif re.search('here.(.+)', cleaned) is not None:\n",
    "            text_clean = re.search('here.(.+)', cleaned).group(1)\n",
    "            clean_transcripts.append(text_clean)\n",
    "    return clean_transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T01:41:31.633235Z",
     "start_time": "2020-07-21T01:41:31.444409Z"
    }
   },
   "outputs": [],
   "source": [
    "cuomo_step2 = clean_cuomo(cuomo_step1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to check whether I was actually pulling transcripts for all of the pages, so I calculated the length for each transcript and looked at the shortest ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T01:41:31.643322Z",
     "start_time": "2020-07-21T01:41:31.634701Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 68,  99, 152,  48,  82,  37, 128,  35, 169,  77,  25,  43, 136,\n",
       "        81,  22,  96, 162,  15,  45,  93, 113, 147, 116, 165, 161, 157,\n",
       "        58,  63, 123,  20, 101,  44,   1,  97, 108,  76,  85,  30,  79,\n",
       "       156,  14,  60, 124, 146, 110,  46, 103,  95,  39, 111,  83, 109,\n",
       "       148, 132,   2, 179, 140, 182,  69,  71,  31,  16, 127,  21,  72,\n",
       "       114,  88, 133, 115, 168, 174,  28,   9, 178,  51,  53,  55, 172,\n",
       "        65, 171,  94, 173, 160,  70, 154,  78,  18,  24, 107,  52,  11,\n",
       "        89, 102,   6,  32,  75,  13, 145,  42,   5, 153, 137,  59,  47,\n",
       "       135,  17,  80,  12, 166,  61, 143, 151,  90, 129, 141,  57, 118,\n",
       "       144,  92,  41,   4,  98,  86,  50,  33,  19, 158, 177, 117, 100,\n",
       "         0, 139, 175, 106, 163, 180,  29, 155, 138, 112, 120, 130,  74,\n",
       "       131,  40, 150,  66,   8, 126,  73,  10,  67,  27, 105,  54,  38,\n",
       "        87, 104, 142, 176,  34,  23, 122, 181, 119,  84,   3, 121, 184,\n",
       "       183,  64, 125,  91,  49, 134,  56, 159,  26, 149,   7, 164,  36,\n",
       "        62, 167, 170])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_len = []\n",
    "for i in cuomo_step2:\n",
    "    test_len.append(len(i))\n",
    "test_len_array = np.array(test_len)\n",
    "test_len_array.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T01:41:31.647859Z",
     "start_time": "2020-07-21T01:41:31.644735Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"and in TV quality (h.264, mp4) format\\xa0here, with ASL interpretation available on YouTube\\xa0here\\xa0and in TV quality format\\xa0here.\\xa0\\xa0AUDIO\\xa0of today's remarks is available\\xa0here.PHOTOS\\xa0are available on the Governor's Flickr\\xa0page.\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuomo_step2[68]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not a valid transcript, so I will be removing this from the list. I'll look at the next shortest one, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T01:41:31.652241Z",
     "start_time": "2020-07-21T01:41:31.649119Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The State has a 1-800 number. It is 1-800-942-6906. That is our domestic violence hotline. Women should know that they don't have to stay in those situations. We will help them relocate. We will help them find safe shelter. And if there is an issue where you are in immediate harm, call 911 immediately. I spoke to the State Police this morning. There is a reported uptick, as you said, some reports as high as 15 to 20 percent. It's unacceptable on any day and I want people to know that in every single case that is reported, the State Police is going to investigate fully and bring the full bear\\xa0of the law behind it.\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuomo_step2[99]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That one looks okay, so I will only delete the shortest transcript from my lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T01:41:31.656368Z",
     "start_time": "2020-07-21T01:41:31.653699Z"
    }
   },
   "outputs": [],
   "source": [
    "delete_index = test_len_array.argsort()[0]\n",
    "del cuomo_step2[delete_index]\n",
    "del cuomolinks_519[delete_index]\n",
    "del cuomo_date[delete_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will put them into a dataframe with the date, link, and transcript text, as I did for the de Blasio transcripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T01:41:31.677190Z",
     "start_time": "2020-07-21T01:41:31.657580Z"
    }
   },
   "outputs": [],
   "source": [
    "cuomo_date = pd.to_datetime(cuomo_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T01:41:31.706035Z",
     "start_time": "2020-07-21T01:41:31.679223Z"
    }
   },
   "outputs": [],
   "source": [
    "cuomo_clean = pd.DataFrame([cuomo_date, cuomolinks_519, cuomo_step2]).T\n",
    "cuomo_clean.columns = ['date', 'links', 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T01:41:31.718618Z",
     "start_time": "2020-07-21T01:41:31.707440Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>links</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-03-19</td>\n",
       "      <td>https://www.governor.ny.gov/news/video-audio-p...</td>\n",
       "      <td>Good morning, everyone. Let me introduce the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>https://www.governor.ny.gov/news/video-audio-p...</td>\n",
       "      <td>The topic today is transportation which is vit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-04</td>\n",
       "      <td>https://www.governor.ny.gov/news/video-audio-p...</td>\n",
       "      <td>We have some good news, we have some bad news....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-28</td>\n",
       "      <td>https://www.governor.ny.gov/news/video-audio-p...</td>\n",
       "      <td>Good afternoon to everyone. I want to introduc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>https://www.governor.ny.gov/news/video-audio-p...</td>\n",
       "      <td>Good morning. Pleasure to be with you. Everybo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>2020-02-04</td>\n",
       "      <td>https://www.governor.ny.gov/news/rush-transcri...</td>\n",
       "      <td>Brian Lehrer: New York's Medicaid program has ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>https://www.governor.ny.gov/news/video-audio-p...</td>\n",
       "      <td>Good afternoon. Lots going on today, coronavir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>2020-03-19</td>\n",
       "      <td>https://www.governor.ny.gov/news/audio-rush-tr...</td>\n",
       "      <td>Alisyn Camerota: Joining us now is New York Go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>https://www.governor.ny.gov/news/video-audio-p...</td>\n",
       "      <td>Good morning. Thank you for being here today.I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>2020-03-24</td>\n",
       "      <td>https://www.governor.ny.gov/news/video-audio-p...</td>\n",
       "      <td>Good morning. Good to see you all here in mask...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>184 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date                                              links  \\\n",
       "0   2020-03-19  https://www.governor.ny.gov/news/video-audio-p...   \n",
       "1   2020-01-23  https://www.governor.ny.gov/news/video-audio-p...   \n",
       "2   2020-03-04  https://www.governor.ny.gov/news/video-audio-p...   \n",
       "3   2020-04-28  https://www.governor.ny.gov/news/video-audio-p...   \n",
       "4   2020-05-01  https://www.governor.ny.gov/news/video-audio-p...   \n",
       "..         ...                                                ...   \n",
       "179 2020-02-04  https://www.governor.ny.gov/news/rush-transcri...   \n",
       "180 2020-04-01  https://www.governor.ny.gov/news/video-audio-p...   \n",
       "181 2020-03-19  https://www.governor.ny.gov/news/audio-rush-tr...   \n",
       "182 2020-03-25  https://www.governor.ny.gov/news/video-audio-p...   \n",
       "183 2020-03-24  https://www.governor.ny.gov/news/video-audio-p...   \n",
       "\n",
       "                                                  text  \n",
       "0    Â Good morning, everyone. Let me introduce the ...  \n",
       "1    The topic today is transportation which is vit...  \n",
       "2    We have some good news, we have some bad news....  \n",
       "3    Good afternoon to everyone. I want to introduc...  \n",
       "4    Good morning. Pleasure to be with you. Everybo...  \n",
       "..                                                 ...  \n",
       "179  Brian Lehrer: New York's Medicaid program has ...  \n",
       "180  Good afternoon. Lots going on today, coronavir...  \n",
       "181  Alisyn Camerota: Joining us now is New York Go...  \n",
       "182  Good morning. Thank you for being here today.I...  \n",
       "183  Good morning. Good to see you all here in mask...  \n",
       "\n",
       "[184 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuomo_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T01:41:31.722389Z",
     "start_time": "2020-07-21T01:41:31.720312Z"
    }
   },
   "outputs": [],
   "source": [
    "# with open('../data/cuomotranscript_519.pickle', 'wb') as to_write:\n",
    "#     pickle.dump(cuomo_clean, to_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I ended up needing to use three different functions using different regular expressions to extract just the parts of the transcript where Cuomo was speaking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T01:41:31.727474Z",
     "start_time": "2020-07-21T01:41:31.724077Z"
    }
   },
   "outputs": [],
   "source": [
    "def take_monologue(transcript):\n",
    "    if len(re.findall('Cuomo:([^:]+)', str(transcript))) > 0:\n",
    "        return str(re.findall('Cuomo:([^:]+)', str(transcript)))\n",
    "    else:\n",
    "        return str(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T01:41:31.733049Z",
     "start_time": "2020-07-21T01:41:31.729026Z"
    }
   },
   "outputs": [],
   "source": [
    "def take_monologue2(transcript):\n",
    "    if len(re.findall('Cuomo:(.*?)[A-Z][a-z]+:', str(transcript))) > 0:\n",
    "        return str(re.findall('Cuomo:(.*?)[A-Z][a-z]+:', str(transcript)))\n",
    "    else:\n",
    "        return str(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T01:41:31.737162Z",
     "start_time": "2020-07-21T01:41:31.734306Z"
    }
   },
   "outputs": [],
   "source": [
    "def take_monologue3(transcript):\n",
    "    if len(re.findall('^(.*?)[A-Z][a-z]+:', str(transcript))) > 0:\n",
    "        return str(re.findall('^(.*?)[A-Z][a-z]+:', str(transcript)))\n",
    "    else:\n",
    "        return str(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T01:41:31.747551Z",
     "start_time": "2020-07-21T01:41:31.738381Z"
    }
   },
   "outputs": [],
   "source": [
    "cuomo_clean['monologue'] = cuomo_clean['text'].map(take_monologue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T01:41:31.788468Z",
     "start_time": "2020-07-21T01:41:31.749549Z"
    }
   },
   "outputs": [],
   "source": [
    "cuomo_clean['monologue2'] = cuomo_clean['text'].map(take_monologue2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T01:41:31.792635Z",
     "start_time": "2020-07-21T01:41:31.789862Z"
    }
   },
   "outputs": [],
   "source": [
    "# Only use third function if the first two don't capture the right transcript\n",
    "def extract_m3(col1, col2):\n",
    "    if (len(col1)-len(col2))/len(col2) > 10:\n",
    "        return take_monologue3(col1)\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T01:41:31.810916Z",
     "start_time": "2020-07-21T01:41:31.793929Z"
    }
   },
   "outputs": [],
   "source": [
    "cuomo_clean['monologue3'] = cuomo_clean.apply(lambda x: extract_m3(x.text, x.monologue), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to keep the longer text, and supplement with the text taken from the third function if it exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T01:41:31.815353Z",
     "start_time": "2020-07-21T01:41:31.812119Z"
    }
   },
   "outputs": [],
   "source": [
    "def compare_two(col1, col2):\n",
    "    if (len(col1)-len(col2))/len(col2) > 1:\n",
    "        return col1\n",
    "    else:\n",
    "        return col2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T01:41:31.828376Z",
     "start_time": "2020-07-21T01:41:31.817112Z"
    }
   },
   "outputs": [],
   "source": [
    "cuomo_clean['final_text'] = cuomo_clean.apply(lambda x: compare_two(x.monologue, x.monologue2), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T01:41:31.834116Z",
     "start_time": "2020-07-21T01:41:31.829845Z"
    }
   },
   "outputs": [],
   "source": [
    "cuomo_clean['final_text2'] = cuomo_clean.monologue3 + cuomo_clean.final_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T01:41:31.837837Z",
     "start_time": "2020-07-21T01:41:31.835445Z"
    }
   },
   "outputs": [],
   "source": [
    "remove_sxa0 = lambda x: x.replace('\\xa0', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T01:41:31.888266Z",
     "start_time": "2020-07-21T01:41:31.839038Z"
    }
   },
   "outputs": [],
   "source": [
    "cuomo_clean['final_clean'] = cuomo_clean['final_text2'].map(punc_lower).map(remove_xa0).map(remove_sxa0).map(remove_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T01:41:31.893877Z",
     "start_time": "2020-07-21T01:41:31.889572Z"
    }
   },
   "outputs": [],
   "source": [
    "cuomo_final = cuomo_clean.loc[:, ['date', 'links', 'text', 'final_clean']]\n",
    "cuomo_final.columns = ['date', 'link', 'text', 'monologue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T01:41:31.897779Z",
     "start_time": "2020-07-21T01:41:31.895176Z"
    }
   },
   "outputs": [],
   "source": [
    "# Include a column indicating this is a transcript from Governor Cuomo\n",
    "cuomo_final.insert(0, 'speaker', 'cuomo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T01:41:31.908215Z",
     "start_time": "2020-07-21T01:41:31.898973Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "      <th>monologue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cuomo</td>\n",
       "      <td>2020-03-19</td>\n",
       "      <td>https://www.governor.ny.gov/news/video-audio-p...</td>\n",
       "      <td>Good morning, everyone. Let me introduce the ...</td>\n",
       "      <td>good morning everyone. let me introduce the pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cuomo</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>https://www.governor.ny.gov/news/video-audio-p...</td>\n",
       "      <td>The topic today is transportation which is vit...</td>\n",
       "      <td>the topic today is transportation which is vit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cuomo</td>\n",
       "      <td>2020-03-04</td>\n",
       "      <td>https://www.governor.ny.gov/news/video-audio-p...</td>\n",
       "      <td>We have some good news, we have some bad news....</td>\n",
       "      <td>we have some good news we have some bad news. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cuomo</td>\n",
       "      <td>2020-04-28</td>\n",
       "      <td>https://www.governor.ny.gov/news/video-audio-p...</td>\n",
       "      <td>Good afternoon to everyone. I want to introduc...</td>\n",
       "      <td>good afternoon to everyone. i want to introduc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cuomo</td>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>https://www.governor.ny.gov/news/video-audio-p...</td>\n",
       "      <td>Good morning. Pleasure to be with you. Everybo...</td>\n",
       "      <td>good morning. pleasure to be with you. everybo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  speaker       date                                               link  \\\n",
       "0   cuomo 2020-03-19  https://www.governor.ny.gov/news/video-audio-p...   \n",
       "1   cuomo 2020-01-23  https://www.governor.ny.gov/news/video-audio-p...   \n",
       "2   cuomo 2020-03-04  https://www.governor.ny.gov/news/video-audio-p...   \n",
       "3   cuomo 2020-04-28  https://www.governor.ny.gov/news/video-audio-p...   \n",
       "4   cuomo 2020-05-01  https://www.governor.ny.gov/news/video-audio-p...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Â Good morning, everyone. Let me introduce the ...   \n",
       "1  The topic today is transportation which is vit...   \n",
       "2  We have some good news, we have some bad news....   \n",
       "3  Good afternoon to everyone. I want to introduc...   \n",
       "4  Good morning. Pleasure to be with you. Everybo...   \n",
       "\n",
       "                                           monologue  \n",
       "0  good morning everyone. let me introduce the pe...  \n",
       "1  the topic today is transportation which is vit...  \n",
       "2  we have some good news we have some bad news. ...  \n",
       "3  good afternoon to everyone. i want to introduc...  \n",
       "4  good morning. pleasure to be with you. everybo...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuomo_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T01:41:31.910802Z",
     "start_time": "2020-07-21T01:41:31.909217Z"
    }
   },
   "outputs": [],
   "source": [
    "# with open('../data/cuomotranscript_519.pickle', 'wb') as to_write:\n",
    "#     pickle.dump(cuomo_final, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
